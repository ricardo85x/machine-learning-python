{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5833f56b00>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(digits.images[2], cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "In machine learning, support vector machines (SVMs, also support vector networks) are supervised max-margin models with associated learning algorithms that analyze data for classification and regression analysis.\n",
    "\n",
    "\n",
    "## Apply SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = digits.data\n",
    "y = digits.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread(\"./assets/imgs/number2.png\")\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    img_array = np.dot(rgb[...,:3], [.299, .587, .114]) # convert rgb\n",
    "    img_array = (16 - (img_array * 16)).astype(int) # convert from 0-1 to 1-16 and invert \n",
    "    img_array = img_array.flatten()\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier.predict([rgb2gray(img)])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(x, y)\n",
    "\n",
    "prediction_logreg = logreg.predict([rgb2gray(img)])\n",
    "print(prediction_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNN is much faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
